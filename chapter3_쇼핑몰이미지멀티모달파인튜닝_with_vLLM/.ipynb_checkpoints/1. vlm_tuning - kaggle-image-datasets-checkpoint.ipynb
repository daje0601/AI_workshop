{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314084a5-620e-4b47-abf7-21dda9f3d7fd",
   "metadata": {},
   "source": [
    "VLM 튜닝 시에서는 디스크 용량을 넉넉하게 확보하고 하시는 게 좋습니다.  \n",
    "Container Disk와 Volume Disk 둘 다 100GB로 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae18ba8-f950-4e87-8f3c-6e5f0ab02b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (11.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "%pip install -q tensorboard wandb \n",
    " \n",
    "# Install Hugging Face libraries\n",
    "%pip install -q --upgrade \\\n",
    "  \"transformers==4.45.1\" \\\n",
    "  \"datasets==3.0.1\" \\\n",
    "  \"accelerate==0.34.2\" \\\n",
    "  \"evaluate==0.4.3\" \\\n",
    "  \"bitsandbytes==0.47.0\" \\\n",
    "  \"trl==0.11.1\" \\\n",
    "  \"peft==0.13.0\" \\\n",
    "  \"qwen-vl-utils\"\n",
    "\n",
    "%pip install \"Pillow>=9.4.0\"\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdb04d-e6f7-4523-b714-d43d712cd20c",
   "metadata": {},
   "source": [
    "패키지 설치 후 혹시모르니 Kerner > Restart Kernel 한 번 눌러주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02234de3-f5a3-4a94-93e0-c18846a01089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import Qwen2VLProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c22022-1417-4c2a-ad0e-6aa7612222dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/womv0mbb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7634df0a0310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361c7a06-fce8-4514-8c8e-7dbbe6652f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템(assistant)에게 주어진 역할\n",
    "system_message = \"당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.\"\n",
    "\n",
    "# 실제로 사용자 입력 -> 모델이 답해야 하는 프롬프트\n",
    "prompt = \"\"\"입력 정보:\n",
    "- name: {name}\n",
    "- image: [image]\n",
    "\n",
    "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
    "1) gender\n",
    "2) masterCategory\n",
    "3) subCategory\n",
    "4) season\n",
    "5) usage\n",
    "6) baseColour\n",
    "7) articleType\n",
    "\n",
    "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
    "{{\n",
    "  \"gender\": \"예시값\",\n",
    "  \"masterCategory\": \"예시값\",\n",
    "  \"subCategory\": \"예시값\",\n",
    "  \"season\": \"예시값\",\n",
    "  \"usage\": \"예시값\",\n",
    "  \"baseColour\": \"예시값\",\n",
    "  \"articleType\": \"예시값\"\n",
    "}}\n",
    "\n",
    "# 예시\n",
    "{{\n",
    "  \"gender\": \"Men\",\n",
    "  \"masterCategory\": \"Accessories\",\n",
    "  \"subCategory\": \"Eyewear\",\n",
    "  \"season\": \"Winter\",\n",
    "  \"usage\": \"Casual\",\n",
    "  \"baseColour\": \"Blue\",\n",
    "  \"articleType\": \"Sunglasses\"\n",
    "}}\n",
    "\n",
    "# 주의\n",
    "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e7eb2f-24f0-4e4b-b47e-d5e1bf680104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_cols_to_label(example):\n",
    "    # 실제 컬럼명에 맞게 수정\n",
    "    label_dict = {\n",
    "        \"gender\": example[\"gender\"],\n",
    "        \"masterCategory\": example[\"masterCategory\"],\n",
    "        \"subCategory\": example[\"subCategory\"],\n",
    "        \"season\": example[\"season\"],\n",
    "        \"usage\": example[\"usage\"],\n",
    "        \"baseColour\": example[\"baseColour\"],\n",
    "        \"articleType\": example[\"articleType\"],\n",
    "    }\n",
    "    example[\"label\"] = json.dumps(label_dict, ensure_ascii=False)\n",
    "    return example\n",
    "\n",
    "def format_data(sample):\n",
    "   # Image.Image를 PngImageFile로 변환\n",
    "   buffer = io.BytesIO()\n",
    "   sample[\"image\"].save(buffer, format='PNG')\n",
    "   buffer.seek(0)\n",
    "   image = Image.open(buffer)\n",
    "   \n",
    "   return {\n",
    "       \"messages\": [\n",
    "           {\n",
    "               \"role\": \"system\",\n",
    "               \"content\": [\n",
    "                   {\n",
    "                       \"type\": \"text\",\n",
    "                       \"text\": system_message\n",
    "                   }\n",
    "               ],\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\",\n",
    "               \"content\": [\n",
    "                   {\n",
    "                       \"type\": \"text\",\n",
    "                       \"text\": prompt.format(name=sample[\"productDisplayName\"]),\n",
    "                   },\n",
    "                   {\n",
    "                       \"type\": \"image\",\n",
    "                       \"image\": image,\n",
    "                   }\n",
    "               ],\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"assistant\",\n",
    "               \"content\": [\n",
    "                   {\n",
    "                       \"type\": \"text\",\n",
    "                       \"text\": sample[\"label\"],\n",
    "                   }\n",
    "               ],\n",
    "           },\n",
    "       ],\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc9b30f-2665-4d47-a290-f9f94c47ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ashraq/fashion-product-images-small\", split=\"train\")\n",
    "dataset_add_label = dataset.map(combine_cols_to_label)\n",
    "dataset_add_label = dataset_add_label.shuffle(seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e348d3-38a3-4223-b0dc-4587dd4cacfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 15516,\n",
       " 'gender': 'Men',\n",
       " 'masterCategory': 'Footwear',\n",
       " 'subCategory': 'Flip Flops',\n",
       " 'articleType': 'Flip Flops',\n",
       " 'baseColour': 'Navy Blue',\n",
       " 'season': 'Fall',\n",
       " 'year': 2011.0,\n",
       " 'usage': 'Casual',\n",
       " 'productDisplayName': 'Rockport Men Altrezlp Navy Blue Flip Flops',\n",
       " 'image': <PIL.Image.Image image mode=RGB size=60x80>,\n",
       " 'label': '{\"gender\": \"Men\", \"masterCategory\": \"Footwear\", \"subCategory\": \"Flip Flops\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Navy Blue\", \"articleType\": \"Flip Flops\"}'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_add_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80992b0-3352-482f-866f-57f60fb2b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_dataset = [format_data(row) for row in dataset_add_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db74a091-8bbf-4dfa-a169-b7a84f611976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '입력 정보:\\n- name: Rockport Men Altrezlp Navy Blue Flip Flops\\n- image: [image]\\n\\n위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\\n1) gender\\n2) masterCategory\\n3) subCategory\\n4) season\\n5) usage\\n6) baseColour\\n7) articleType\\n\\n출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\\n{\\n  \"gender\": \"예시값\",\\n  \"masterCategory\": \"예시값\",\\n  \"subCategory\": \"예시값\",\\n  \"season\": \"예시값\",\\n  \"usage\": \"예시값\",\\n  \"baseColour\": \"예시값\",\\n  \"articleType\": \"예시값\"\\n}\\n\\n# 예시\\n{\\n  \"gender\": \"Men\",\\n  \"masterCategory\": \"Accessories\",\\n  \"subCategory\": \"Eyewear\",\\n  \"season\": \"Winter\",\\n  \"usage\": \"Casual\",\\n  \"baseColour\": \"Blue\",\\n  \"articleType\": \"Sunglasses\"\\n}\\n\\n# 주의\\n- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\\n'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '{\"gender\": \"Men\", \"masterCategory\": \"Footwear\", \"subCategory\": \"Flip Flops\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Navy Blue\", \"articleType\": \"Flip Flops\"}'}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa7b51c-9b4d-47b5-8811-23aa1d3e41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size=0.9로 설정하여 전체 데이터의 90%를 테스트 세트로 분리\n",
    "train_dataset, test_dataset = train_test_split(formatted_dataset,\n",
    "                                             test_size=0.9,\n",
    "                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f870de25-a37a-4e5b-a1b4-fef198d72315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터의 개수: 4407\n",
      "테스트 데이터의 개수: 39665\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터의 개수:', len(train_dataset))\n",
    "print('테스트 데이터의 개수:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b0fbdb-5db4-41a8-9ee3-883d8f5dfed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe364b5c8742d5a9ef6cc68bf50ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 모델 ID\n",
    "model_id = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"auto\",                            # GPU 메모리에 자동 할당\n",
    "   torch_dtype=torch.bfloat16,                   # bfloat16 정밀도 사용\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)  # 텍스트/이미지 전처리기 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "322ca1ea-30a7-4250-800f-cc6592c0d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "입력 정보:\n",
      "- name: Mr.Men Men's Charcoal White T-shirt\n",
      "- image: [image]\n",
      "\n",
      "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
      "1) gender\n",
      "2) masterCategory\n",
      "3) subCategory\n",
      "4) season\n",
      "5) usage\n",
      "6) baseColour\n",
      "7) articleType\n",
      "\n",
      "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
      "{\n",
      "  \"gender\": \"예시값\",\n",
      "  \"masterCategory\": \"예시값\",\n",
      "  \"subCategory\": \"예시값\",\n",
      "  \"season\": \"예시값\",\n",
      "  \"usage\": \"예시값\",\n",
      "  \"baseColour\": \"예시값\",\n",
      "  \"articleType\": \"예시값\"\n",
      "}\n",
      "\n",
      "# 예시\n",
      "{\n",
      "  \"gender\": \"Men\",\n",
      "  \"masterCategory\": \"Accessories\",\n",
      "  \"subCategory\": \"Eyewear\",\n",
      "  \"season\": \"Winter\",\n",
      "  \"usage\": \"Casual\",\n",
      "  \"baseColour\": \"Blue\",\n",
      "  \"articleType\": \"Sunglasses\"\n",
      "}\n",
      "\n",
      "# 주의\n",
      "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
      "<|vision_start|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"gender\": \"Men\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Topwear\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Grey\", \"articleType\": \"Tshirts\"}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    train_dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e182a4db-d71e-48f1-9de6-fe88d602af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "       # 모델 가중치에 LoRA 업데이트를 적용하는 정도를 조절하는 스케일링 계수\n",
    "       lora_alpha=128,\n",
    "       # 과적합을 방지하기 위한 드롭아웃 비율 설정\n",
    "       lora_dropout=0.05,\n",
    "       # LoRA의 순위(rank) - 저차원 행렬의 차원을 결정\n",
    "       r=256,\n",
    "       # 편향(bias) 업데이트 여부 - 'none'은 편향을 업데이트하지 않음\n",
    "       bias=\"none\",\n",
    "       # LoRA를 적용할 대상 모듈들 - 트랜스포머 모델의 주요 투영 레이어들\n",
    "       target_modules=[\n",
    "           \"q_proj\",    # Query 투영 레이어\n",
    "           \"up_proj\",   # FFN 상향 투영 레이어\n",
    "           \"o_proj\",    # Output 투영 레이어\n",
    "           \"k_proj\",    # Key 투영 레이어\n",
    "           \"down_proj\", # FFN 하향 투영 레이어\n",
    "           \"gate_proj\", # FFN 게이트 투영 레이어\n",
    "           \"v_proj\"     # Value 투영 레이어\n",
    "       ],\n",
    "       # 작업 유형 지정 - 인과적 언어 모델링(다음 토큰 예측)\n",
    "       task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dc0fb20-9c67-4a76-8882-9f81724e602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir=\"output_dir\",           # 저장될 디렉토리와 저장소 ID\n",
    "    num_train_epochs=2,                      # 학습할 총 에포크 수 \n",
    "    per_device_train_batch_size=16,           # GPU당 배치 크기\n",
    "    gradient_accumulation_steps=8,           # 그래디언트 누적 스텝 수\n",
    "    gradient_checkpointing=True,             # 메모리 절약을 위한 체크포인팅\n",
    "    optim=\"adamw_torch_fused\",               # 최적화기\n",
    "    logging_steps=10,                        # 로그 기록 주기\n",
    "    save_strategy=\"steps\",                   # 저장 전략\n",
    "    save_steps=50,                           # 저장 주기\n",
    "    bf16=True,                              # bfloat16 사용\n",
    "    learning_rate=1e-4,                     # 학습률\n",
    "    max_grad_norm=0.3,                      # 그래디언트 클리핑\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율\n",
    "    lr_scheduler_type=\"constant\",           # 고정 학습률\n",
    "    push_to_hub=False,                      # 허브 업로드 안 함\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8196baaa-f31e-4514-891d-ce5fc302d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "   \"\"\"\n",
    "   텍스트와 이미지가 포함된 대화 데이터를 모델 학습에 적합한 형태로 변환하는 함수\n",
    "   \n",
    "   Args:\n",
    "       examples: 각각 \"messages\" 키를 가진 딕셔너리들의 리스트\n",
    "                messages는 role(system/user/assistant)과 content를 포함하는 대화 형태\n",
    "   \n",
    "   Returns:\n",
    "       batch: 모델 학습에 사용할 수 있는 토큰화된 텍스트, 이미지, 라벨이 포함된 배치\n",
    "   \"\"\"\n",
    "   \n",
    "   # 1단계: 텍스트 전처리 - 채팅 템플릿 적용\n",
    "   # 각 예제의 messages를 모델 고유의 채팅 형식으로 변환\n",
    "   # 모델마다 다른 특수 토큰과 형식을 사용 (예: <|im_start|>, <|system|> 등)\n",
    "   texts = [processor.apply_chat_template(example[\"messages\"], tokenize=False) for example in examples]\n",
    "   \n",
    "   # 2단계: 이미지 데이터 추출 및 전처리\n",
    "   # messages에서 이미지 정보를 추출하여 모델이 처리할 수 있는 형태로 변환\n",
    "   # process_vision_info()는 messages에서 이미지를 찾아 적절한 형태로 변환해주는 함수\n",
    "   image_inputs = [process_vision_info(example[\"messages\"])[0] for example in examples]\n",
    "\n",
    "   # 3단계: 텍스트 토크나이징 + 이미지 인코딩\n",
    "   # 텍스트를 토큰으로 변환하고 이미지를 인코딩하여 하나의 배치로 묶음\n",
    "   # return_tensors=\"pt\": PyTorch 텐서 형태로 반환\n",
    "   # padding=True: 배치 내 모든 시퀀스를 같은 길이로 맞춤 (짧은 것은 패딩 토큰으로 채움)\n",
    "   batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "   # 4단계: 라벨 생성 (손실 계산용)\n",
    "   # input_ids를 복사하여 라벨로 사용 (다음 토큰 예측 학습을 위함)\n",
    "   labels = batch[\"input_ids\"].clone()\n",
    "   \n",
    "   # 5단계: 패딩 토큰 손실 계산에서 제외\n",
    "   # 패딩된 부분은 실제 데이터가 아니므로 손실 계산에서 제외\n",
    "   # -100으로 설정하면 CrossEntropyLoss에서 자동으로 무시됨\n",
    "   labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "   # 6단계: 이미지 토큰 손실 계산에서 제외\n",
    "   # 이미지 토큰은 예측 대상이 아니므로 손실 계산에서 제외\n",
    "   if isinstance(processor, Qwen2VLProcessor):\n",
    "       # Qwen2VL 모델에서 사용하는 특수 이미지 토큰들의 ID\n",
    "       # 151652: 이미지 시작 토큰, 151653: 이미지 종료 토큰, 151655: 이미지 패치 토큰\n",
    "       image_tokens = [151652, 151653, 151655]\n",
    "   else:\n",
    "       # 다른 비전-언어 모델의 이미지 토큰 ID 추출\n",
    "       image_tokens = [processor.tokenizer.convert_tokens_to_ids(processor.image_token)]\n",
    "   \n",
    "   # 이미지 토큰들을 손실 계산에서 제외 (-100으로 설정)\n",
    "   for image_token_id in image_tokens:\n",
    "       labels[labels == image_token_id] = -100\n",
    "\n",
    "   # 7단계: 최종 배치에 라벨 추가\n",
    "   # 모델 학습 시 손실 계산에 사용될 라벨을 배치에 추가\n",
    "   batch[\"labels\"] = labels\n",
    "\n",
    "   return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c3a62ef-06b4-41d8-97ae-5aa2f2a3c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일 예시 데이터:\n",
      "{'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': '당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': '입력 정보:\\n- name: Mr.Men Men\\'s Charcoal White T-shirt\\n- image: [image]\\n\\n위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\\n1) gender\\n2) masterCategory\\n3) subCategory\\n4) season\\n5) usage\\n6) baseColour\\n7) articleType\\n\\n출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\\n{\\n  \"gender\": \"예시값\",\\n  \"masterCategory\": \"예시값\",\\n  \"subCategory\": \"예시값\",\\n  \"season\": \"예시값\",\\n  \"usage\": \"예시값\",\\n  \"baseColour\": \"예시값\",\\n  \"articleType\": \"예시값\"\\n}\\n\\n# 예시\\n{\\n  \"gender\": \"Men\",\\n  \"masterCategory\": \"Accessories\",\\n  \"subCategory\": \"Eyewear\",\\n  \"season\": \"Winter\",\\n  \"usage\": \"Casual\",\\n  \"baseColour\": \"Blue\",\\n  \"articleType\": \"Sunglasses\"\\n}\\n\\n# 주의\\n- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\\n'}, {'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80 at 0x763484BF1910>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '{\"gender\": \"Men\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Topwear\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Grey\", \"articleType\": \"Tshirts\"}'}]}]}\n",
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 365])\n",
      "어텐션 마스크 형태: torch.Size([1, 365])\n",
      "이미지 픽셀 형태: torch.Size([24, 1176])\n",
      "레이블 형태: torch.Size([1, 365])\n"
     ]
    }
   ],
   "source": [
    "# 단일 예시 확인\n",
    "example = train_dataset[0]  # 데이터셋의 첫 번째 아이템\n",
    "print(\"단일 예시 데이터:\")\n",
    "print(example)\n",
    "\n",
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "batch = collate_fn([example])\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"이미지 픽셀 형태:\", batch[\"pixel_values\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e5a42f-b871-4d7b-b2db-a61b85d1a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "tensor([151644,   8948,    198,  64795,  82528,  33704,  90667,  21329,  80573,\n",
      "        138017,  79632,   3153,      8,  42039, 126558,  45104,    101,  92031,\n",
      "            14, 141274,  32077,  60039,  18411,  57835, 126605,  42905, 128618,\n",
      "         97929,  54070, 142713,  78952,     13, 151645,    198, 151644,    872,\n",
      "           198,  43866,  28754,  60039,    510,     12,    829,     25,   4392,\n",
      "          1321,    268,  11012,    594,   4864,  40465,   5807,    350,  33668,\n",
      "           198,     12,   2168,     25,    508,   1805,   2533,  80901,  60039,\n",
      "         18411,  81718, 144059,  42039,     11, 136646,    220,     22,  19969,\n",
      "         21329,   1376,  19391, 128605,  93668,   4718, 141966,  17380,  57835,\n",
      "        126605,  33883,  55673,  50302,    510,     16,      8,   9825,    198,\n",
      "            17,      8,   7341,   6746,    198,     18,      8,   1186,   6746,\n",
      "           198,     19,      8,   3200,    198,     20,      8,  10431,    198,\n",
      "            21,      8,   2331,  33281,    198,     22,      8,   4549,    929,\n",
      "           271,  53496,  57133,  44518,   3070,  52959,  53442,   4718,  95617,\n",
      "         29326, 141966,    334,  18411, 141762,  66790, 126896,  50302,    510,\n",
      "           515,    220,    330,  12968,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,  13629,   6746,    788,    330, 127027,  29326,\n",
      "         82801,    756,    220,    330,   1966,   6746,    788,    330, 127027,\n",
      "         29326,  82801,    756,    220,    330,  16798,    788,    330, 127027,\n",
      "         29326,  82801,    756,    220,    330,  17698,    788,    330, 127027,\n",
      "         29326,  82801,    756,    220,    330,   3152,  33281,    788,    330,\n",
      "        127027,  29326,  82801,    756,    220,    330,   7058,    929,    788,\n",
      "           330, 127027,  29326,  82801,    698,    630,      2,  95617,  29326,\n",
      "           198,    515,    220,    330,  12968,    788,    330,  28719,    756,\n",
      "           220,    330,  13629,   6746,    788,    330,   6054,   2433,    756,\n",
      "           220,    330,   1966,   6746,    788,    330,  97454,  98128,    756,\n",
      "           220,    330,  16798,    788,    330,  66188,    756,    220,    330,\n",
      "         17698,    788,    330,  49242,    928,    756,    220,    330,   3152,\n",
      "         33281,    788,    330,  10331,    756,    220,    330,   7058,    929,\n",
      "           788,    330,     50,   2185,  33868,    698,    630,      2,  55673,\n",
      "         20401,    198,     12,    220,     22,  59761, 142654,  87608,  23084,\n",
      "        128792,  20401,  60039,      7, 144153,  53189,     11,  53435,  40853,\n",
      "         77002,      8,  16560,  18585,    230,  66845, 133970,  87425,  95577,\n",
      "         50302,    624, 151652, 151655, 151655, 151655, 151655, 151655, 151655,\n",
      "        151653, 151645,    198, 151644,  77091,    198,   4913,  12968,    788,\n",
      "           330,  28719,    497,    330,  13629,   6746,    788,    330,   2164,\n",
      "         30431,    497,    330,   1966,   6746,    788,    330,   5366,  22744,\n",
      "           497,    330,  16798,    788,    330,  49772,    497,    330,  17698,\n",
      "           788,    330,  49242,    928,    497,    330,   3152,  33281,    788,\n",
      "           330,  59165,    497,    330,   7058,    929,    788,    330,     51,\n",
      "           927,  19666,   9207, 151645,    198])\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "566ab87a-7417-4c5b-b3b5-2733565bfe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블에 대한 정수 인코딩 결과:\n",
      "tensor([151644,   8948,    198,  64795,  82528,  33704,  90667,  21329,  80573,\n",
      "        138017,  79632,   3153,      8,  42039, 126558,  45104,    101,  92031,\n",
      "            14, 141274,  32077,  60039,  18411,  57835, 126605,  42905, 128618,\n",
      "         97929,  54070, 142713,  78952,     13, 151645,    198, 151644,    872,\n",
      "           198,  43866,  28754,  60039,    510,     12,    829,     25,   4392,\n",
      "          1321,    268,  11012,    594,   4864,  40465,   5807,    350,  33668,\n",
      "           198,     12,   2168,     25,    508,   1805,   2533,  80901,  60039,\n",
      "         18411,  81718, 144059,  42039,     11, 136646,    220,     22,  19969,\n",
      "         21329,   1376,  19391, 128605,  93668,   4718, 141966,  17380,  57835,\n",
      "        126605,  33883,  55673,  50302,    510,     16,      8,   9825,    198,\n",
      "            17,      8,   7341,   6746,    198,     18,      8,   1186,   6746,\n",
      "           198,     19,      8,   3200,    198,     20,      8,  10431,    198,\n",
      "            21,      8,   2331,  33281,    198,     22,      8,   4549,    929,\n",
      "           271,  53496,  57133,  44518,   3070,  52959,  53442,   4718,  95617,\n",
      "         29326, 141966,    334,  18411, 141762,  66790, 126896,  50302,    510,\n",
      "           515,    220,    330,  12968,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,  13629,   6746,    788,    330, 127027,  29326,\n",
      "         82801,    756,    220,    330,   1966,   6746,    788,    330, 127027,\n",
      "         29326,  82801,    756,    220,    330,  16798,    788,    330, 127027,\n",
      "         29326,  82801,    756,    220,    330,  17698,    788,    330, 127027,\n",
      "         29326,  82801,    756,    220,    330,   3152,  33281,    788,    330,\n",
      "        127027,  29326,  82801,    756,    220,    330,   7058,    929,    788,\n",
      "           330, 127027,  29326,  82801,    698,    630,      2,  95617,  29326,\n",
      "           198,    515,    220,    330,  12968,    788,    330,  28719,    756,\n",
      "           220,    330,  13629,   6746,    788,    330,   6054,   2433,    756,\n",
      "           220,    330,   1966,   6746,    788,    330,  97454,  98128,    756,\n",
      "           220,    330,  16798,    788,    330,  66188,    756,    220,    330,\n",
      "         17698,    788,    330,  49242,    928,    756,    220,    330,   3152,\n",
      "         33281,    788,    330,  10331,    756,    220,    330,   7058,    929,\n",
      "           788,    330,     50,   2185,  33868,    698,    630,      2,  55673,\n",
      "         20401,    198,     12,    220,     22,  59761, 142654,  87608,  23084,\n",
      "        128792,  20401,  60039,      7, 144153,  53189,     11,  53435,  40853,\n",
      "         77002,      8,  16560,  18585,    230,  66845, 133970,  87425,  95577,\n",
      "         50302,    624,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100, 151645,    198, 151644,  77091,    198,   4913,  12968,    788,\n",
      "           330,  28719,    497,    330,  13629,   6746,    788,    330,   2164,\n",
      "         30431,    497,    330,   1966,   6746,    788,    330,   5366,  22744,\n",
      "           497,    330,  16798,    788,    330,  49772,    497,    330,  17698,\n",
      "           788,    330,  49242,    928,    497,    330,   3152,  33281,    788,\n",
      "           330,  59165,    497,    330,   7058,    929,    788,    330,     51,\n",
      "           927,  19666,   9207, 151645,    198])\n"
     ]
    }
   ],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b671c6c0-ca49-467d-b427-df6f9c0cd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "디코딩된 텍스트:\n",
      "<|im_start|>system\n",
      "당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "입력 정보:\n",
      "- name: Mr.Men Men's Charcoal White T-shirt\n",
      "- image: [image]\n",
      "\n",
      "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
      "1) gender\n",
      "2) masterCategory\n",
      "3) subCategory\n",
      "4) season\n",
      "5) usage\n",
      "6) baseColour\n",
      "7) articleType\n",
      "\n",
      "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
      "{\n",
      "  \"gender\": \"예시값\",\n",
      "  \"masterCategory\": \"예시값\",\n",
      "  \"subCategory\": \"예시값\",\n",
      "  \"season\": \"예시값\",\n",
      "  \"usage\": \"예시값\",\n",
      "  \"baseColour\": \"예시값\",\n",
      "  \"articleType\": \"예시값\"\n",
      "}\n",
      "\n",
      "# 예시\n",
      "{\n",
      "  \"gender\": \"Men\",\n",
      "  \"masterCategory\": \"Accessories\",\n",
      "  \"subCategory\": \"Eyewear\",\n",
      "  \"season\": \"Winter\",\n",
      "  \"usage\": \"Casual\",\n",
      "  \"baseColour\": \"Blue\",\n",
      "  \"articleType\": \"Sunglasses\"\n",
      "}\n",
      "\n",
      "# 주의\n",
      "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"gender\": \"Men\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Topwear\", \"season\": \"Fall\", \"usage\": \"Casual\", \"baseColour\": \"Grey\", \"articleType\": \"Tshirts\"}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토큰 디코딩 예시 (입력 텍스트가 어떻게 변환되었는지 확인)\n",
    "decoded_text = processor.tokenizer.decode(batch[\"input_ids\"][0])\n",
    "print(\"\\n디코딩된 텍스트:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63b5e71b-4db7-4343-b80d-5ffeb839a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so')}\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=128, Highest Compute Capability: 8.0.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Required library version not found: libbitsandbytes_cuda128.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. You need to manually override the PyTorch CUDA version. Please see: \"https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "2. CUDA driver not installed\n",
      "3. CUDA not installed\n",
      "4. You have multiple conflicting CUDA libraries\n",
      "5. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
      "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Something unexpected happened. Please compile from source:\n",
      "git clone https://github.com/TimDettmers/bitsandbytes.git\n",
      "cd bitsandbytes\n",
      "CUDA_VERSION=128\n",
      "python setup.py install\n",
      "CUDA SETUP: Setup Failed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: /usr/local/cuda/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer = \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:268\u001b[39m, in \u001b[36mSFTTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size, neftune_noise_alpha, model_init_kwargs, dataset_kwargs, eval_packing)\u001b[39m\n\u001b[32m    266\u001b[39m     model = get_peft_model(model, peft_config, autocast_adapter_dtype=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     model = \u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    270\u001b[39m     args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    271\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m args.bf16\n\u001b[32m    272\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mis_loaded_in_4bit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    273\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sharded_qlora\n\u001b[32m    274\u001b[39m ):\n\u001b[32m    275\u001b[39m     peft_module_casting_to_bf16(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/mapping.py:193\u001b[39m, in \u001b[36mget_peft_model\u001b[39m\u001b[34m(model, peft_config, adapter_name, mixed, autocast_adapter_dtype, revision)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m peft_config.is_prompt_learning:\n\u001b[32m    192\u001b[39m     peft_config = _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautocast_adapter_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautocast_adapter_dtype\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:1609\u001b[39m, in \u001b[36mPeftModelForCausalLM.__init__\u001b[39m\u001b[34m(self, model, peft_config, adapter_name, **kwargs)\u001b[39m\n\u001b[32m   1606\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m   1607\u001b[39m     \u001b[38;5;28mself\u001b[39m, model: torch.nn.Module, peft_config: PeftConfig, adapter_name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m, **kwargs\n\u001b[32m   1608\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1609\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1610\u001b[39m     \u001b[38;5;28mself\u001b[39m.base_model_prepare_inputs_for_generation = \u001b[38;5;28mself\u001b[39m.base_model.prepare_inputs_for_generation\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:171\u001b[39m, in \u001b[36mPeftModel.__init__\u001b[39m\u001b[34m(self, model, peft_config, adapter_name, autocast_adapter_dtype, low_cpu_mem_usage)\u001b[39m\n\u001b[32m    169\u001b[39m     ctx = init_empty_weights \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28mself\u001b[39m.base_model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_additional_trainable_modules(peft_config, adapter_name)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.base_model, \u001b[33m\"\u001b[39m\u001b[33m_cast_adapter_dtype\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py:141\u001b[39m, in \u001b[36mLoraModel.__init__\u001b[39m\u001b[34m(self, model, config, adapter_name, low_cpu_mem_usage)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, config, adapter_name, low_cpu_mem_usage: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:184\u001b[39m, in \u001b[36mBaseTuner.__init__\u001b[39m\u001b[34m(self, model, peft_config, adapter_name, low_cpu_mem_usage)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m._pre_injection_hook(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.peft_config[adapter_name], adapter_name)\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m peft_config != PeftType.XLORA \u001b[38;5;129;01mor\u001b[39;00m peft_config[adapter_name] != PeftType.XLORA:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minject_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# Copy the peft_config in the injected model.\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m.model.peft_config = \u001b[38;5;28mself\u001b[39m.peft_config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:494\u001b[39m, in \u001b[36mBaseTuner.inject_adapter\u001b[39m\u001b[34m(self, model, adapter_name, autocast_adapter_dtype, low_cpu_mem_usage)\u001b[39m\n\u001b[32m    492\u001b[39m     ctx = init_empty_weights \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx():\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_and_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m tied_target_modules = \u001b[38;5;28mself\u001b[39m._get_tied_target_modules(model=model)\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tied_target_modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py:226\u001b[39m, in \u001b[36mLoraModel._create_and_replace\u001b[39m\u001b[34m(self, lora_config, adapter_name, target, target_name, parent, current_key)\u001b[39m\n\u001b[32m    216\u001b[39m     target.update_layer(\n\u001b[32m    217\u001b[39m         adapter_name,\n\u001b[32m    218\u001b[39m         r,\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m         use_dora=lora_config.use_dora,\n\u001b[32m    224\u001b[39m     )\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     new_module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_new_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m adapter_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_adapters:\n\u001b[32m    228\u001b[39m         \u001b[38;5;66;03m# adding an additional adapter: it is not automatically trainable\u001b[39;00m\n\u001b[32m    229\u001b[39m         new_module.requires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py:321\u001b[39m, in \u001b[36mLoraModel._create_new_module\u001b[39m\u001b[34m(lora_config, adapter_name, target, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# avoid eager bnb import\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_available():\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbnb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch_bnb_8bit\n\u001b[32m    323\u001b[39m     dispatchers.append(dispatch_bnb_8bit)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_4bit_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbnb\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpeft\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bnb_4bit_available, is_bnb_available\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     MatmulLtState,\n\u001b[32m      9\u001b[39m     bmm_cublas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     matmul_4bit\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/research/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     switchback_bnb,\n\u001b[32m      4\u001b[39m     matmul_fp8_global,\n\u001b[32m      5\u001b[39m     matmul_fp8_mixed,\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/research/nn/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/research/nn/modules.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbnb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[32m     11\u001b[39m T = TypeVar(\u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, bound=\u001b[33m\"\u001b[39m\u001b[33mtorch.nn.Module\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/optim/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01madagrad\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01madam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py:20\u001b[39m\n\u001b[32m     18\u001b[39m     CUDASetup.get_instance().generate_instructions()\n\u001b[32m     19\u001b[39m     CUDASetup.get_instance().print_log_stack()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'''\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33m    python -m bitsandbytes\u001b[39m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[33m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[33m'''\u001b[39m)\n\u001b[32m     28\u001b[39m lib.cadam32bit_grad_fp32 \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n\u001b[32m     29\u001b[39m lib.get_context.restype = ct.c_void_p\n",
      "\u001b[31mRuntimeError\u001b[39m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=processor.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18243c0b-f767-47fd-a84c-d9923145686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시작\n",
    "trainer.train()   # 모델이 자동으로 허브와 output_dir에 저장됨\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model()   # 최종 모델을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d29cd0-e9b5-4830-8f7c-956aa8872a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
